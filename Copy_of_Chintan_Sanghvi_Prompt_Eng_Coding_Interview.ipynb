{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csanghvi-stripe/advanced-css-course/blob/master/Copy_of_Chintan_Sanghvi_Prompt_Eng_Coding_Interview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augmented Generation with Claude\n",
        "## Introduction\n",
        "In the following exercise, we are going to implement a technique known as [Retrieval Augmented Generation (RAG)](https://www.promptingguide.ai/techniques/rag). RAG is a way to let Claude interact with external data (such as text documents) and use information from that data to craft its response. This can be useful in all kinds of contexts, from analyzing financial documents to customer service.\n",
        "\n",
        "## Our Use Case: Wikipedia Search\n",
        "Claude has a serious problem. It doesn't know anything about the world after its training cutoff date. One way to fix this is to give it access to current sources of information using RAG. In this exercise, you are going to give Claude access to one such information source: Wikipedia. If done properly, your new version of Claude, ClaWd, should be able to search wikipedia for relevant (and current) information to include in its answers.\n",
        "\n",
        "This challenge is part coding, part prompting, part system design. We leave it up to you to think about how you might accomplish this task, but provide you a few code snippets you may find helpful below. It is not required that you use all of these."
      ],
      "metadata": {
        "id": "pWkkuulhyyx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gctMxlFzATgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Useful Code (Maybe)"
      ],
      "metadata": {
        "id": "tIE-Y5nYD-uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U typing-extensions\n",
        "!pip install anthropic\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "fGumS80I_8jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "import wikipedia\n",
        "\n",
        "API_KEY = \"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\"  # anthropic api key\n",
        "MODEL_NAME = \"claude-2.1\"\n",
        "client = anthropic.Anthropic(api_key=API_KEY)\n",
        "\n",
        "def get_completion(prompt: str):\n",
        "    message = client.beta.messages.create(\n",
        "        model=MODEL_NAME,\n",
        "        max_tokens=1024,\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text\n",
        "\n",
        "def get_wikipedia_search_results(query: str, n_search_results_to_use=1):\n",
        "  \"\"\"Call the wikipedia API and get back article content, title, and source.\"\"\"\n",
        "  results: list[str] = wikipedia.search(query)\n",
        "  search_results: list[dict] = []\n",
        "  for result in results:\n",
        "    if len(search_results) >= n_search_results_to_use:\n",
        "      break\n",
        "    try:\n",
        "      page = wikipedia.page(result)\n",
        "    except:\n",
        "      # The Wikipedia API is a little flaky, so we just skip over pages that fail to load\n",
        "      continue\n",
        "\n",
        "    search_result = {\n",
        "        \"content\": page.content,\n",
        "        \"title\": page.title,\n",
        "        \"source\": page.url\n",
        "    }\n",
        "\n",
        "    search_results.append(search_result)\n",
        "\n",
        "    tokenizer = anthropic.Anthropic().get_tokenizer()\n",
        "    # Trim down the number of tokens per article (this will make your life easier in this interview, in practice you might not always want to do it)\n",
        "    for search_result in search_results:\n",
        "      search_result['content'] = tokenizer.decode(tokenizer.encode(search_result['content']).ids[:5000])\n",
        "  return search_results"
      ],
      "metadata": {
        "id": "GIqhT8GXDyd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Answer Questions with Wikipedia\n",
        "Please complete the function ask_clawd() below so that Claude can answer questions using Wikipedia data.\n",
        "\n",
        "Focus on the *quality* of your generated answers over their *latency*."
      ],
      "metadata": {
        "id": "WSXgOfHKLA0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_clawd(query: str):\n",
        "  pass"
      ],
      "metadata": {
        "id": "736TYdJBMxFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Sample Uses (feel free to add more)"
      ],
      "metadata": {
        "id": "t673C0GcM5nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What's the name of the latest material that was claimed to be a room temperature superconductor?\",\n",
        "    \"Who is the US Speaker of the House?\",\n",
        "    \"Which team won the college football national championship in 2024?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "  print(f\"-------------{question}-------------\")\n",
        "  print(ask_clawd(question))"
      ],
      "metadata": {
        "id": "97wCv17hNBX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Make a multiple choice test\n",
        "Now that you have a way to work with Wikipedia data in Claude, let's do something more useful with it.\n",
        "\n",
        "Please complete the function generate_test_with_clawd() below so that Claude generates a 3 question multiple choice test about a given subject, where each question has four options, only one of which is true.\n",
        "\n",
        "Focus on the quality of your generated answers over their latency."
      ],
      "metadata": {
        "id": "a9SFTLddO2ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_with_clawd(subject: str):\n",
        "  pass"
      ],
      "metadata": {
        "id": "oU8-IXkWRvMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Sample Uses (feel free to add more)"
      ],
      "metadata": {
        "id": "CD4Q2CrDR5mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = [\n",
        "    \"The French Revolution\",\n",
        "    \"Covid-19 in 2023\"\n",
        "]\n",
        "\n",
        "for subject in subjects:\n",
        "  print(f\"-------------{subject}-------------\")\n",
        "  print(generate_test_with_clawd(subject))"
      ],
      "metadata": {
        "id": "jucSz05-R6jL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}